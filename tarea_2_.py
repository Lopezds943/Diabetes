# -*- coding: utf-8 -*-
"""Tarea 2 .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TEC314LUGqjNuhyQJFk953LtLvONvmQL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OrdinalEncoder
from sklearn.feature_selection import SelectKBest, chi2, f_classif
from matplotlib import pyplot
from sklearn.impute import SimpleImputer

from ucimlrepo import fetch_ucirepo

# fetch dataset
diabetes_130_us_hospitals_for_years_1999_2008 = fetch_ucirepo(id=296)

# data (as pandas dataframes)
X = diabetes_130_us_hospitals_for_years_1999_2008.data.features
y = diabetes_130_us_hospitals_for_years_1999_2008.data.targets

# Combinar en un solo DataFrame
df = pd.concat([X, y], axis=1)

# Mostrar primeras filas
df.head()

# ----------------- CONFIG Valores -----------------
TARGET_COL    = "readmitted"     # nombre del target
CUM_THRESHOLD = 0.80             # porcentaje acumulado (ej: 0.80 = 80%)
METHOD        = "cat_chi2"       # "cat_chi2" (categóricas) o "num_f" (numéricas)

# ---------------------------------------------------------------
# Cargar datos y separar X/y
# ---------------------------------------------------------------
X = df.drop(columns=[TARGET_COL])
y = df[TARGET_COL]

# ---------------------------------------------------------------
# Elegir columnas categoricas
# ---------------------------------------------------------------
if METHOD == "cat_chi2":
    cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    if len(cols) == 0:
        raise ValueError("No hay columnas categóricas para Chi².")
elif METHOD == "num_f":
    cols = X.select_dtypes(include=[np.number]).columns.tolist()
    if len(cols) == 0:
        raise ValueError("No hay columnas numéricas para ANOVA F-test.")
else:
    raise ValueError("METHOD debe ser 'cat_chi2' o 'num_f'.")

X_use = X[cols].copy()

# ---------------------------------------------------------------
# Train/Test split (estratificado) y codificación del target
# ---------------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X_use, y, test_size=0.30, random_state=42, stratify=y
)

lab_y = LabelEncoder()
y_train_enc = lab_y.fit_transform(y_train)
y_test_enc  = lab_y.transform(y_test)

# ---------------------------------------------------------------
# Calcular "scores" según técnica del notebook
# ---------------------------------------------------------------
if METHOD == "cat_chi2":
    # Rellenar vacíos con 'MISSING' para no perder filas
    X_train_f = X_train.fillna('MISSING')

    # OrdinalEncoder (como en el notebook); unknown -> -1
    ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
    X_train_enc = ord_enc.fit_transform(X_train_f)

    # Desplazar +1 para que todo sea >= 0 (Chi² lo requiere)
    X_train_enc = X_train_enc + 1

    # Chi² sobre TODAS las columnas (k='all') para obtener score por variable
    selector_all = SelectKBest(score_func=chi2, k='all')
    selector_all.fit(X_train_enc, y_train_enc)

    scores = np.nan_to_num(selector_all.scores_, nan=0.0)
    rank = (
        pd.DataFrame({'feature': cols, 'score': scores})
        .sort_values('score', ascending=False)
        .reset_index(drop=True)
    )

elif METHOD == "num_f":
    # ANOVA F-test sobre numéricas (no necesita encoding)
    selector_all = SelectKBest(score_func=f_classif, k='all')
    selector_all.fit(X_train.values, y_train_enc)

    scores = np.nan_to_num(selector_all.scores_, nan=0.0)
    rank = (
        pd.DataFrame({'feature': cols, 'score': scores})
        .sort_values('score', ascending=False)
        .reset_index(drop=True)
    )

# ---------------------------------------------------------------
# Selección por % acumulado (score normalizado)
# ---------------------------------------------------------------
total = rank['score'].sum()
if total == 0:
    # Si todos los scores son 0, nos quedamos con la primera para cumplir
    rank['norm'] = 0.0
    rank['cum_pct'] = 0.0
    cut_idx = 0
else:
    rank['norm'] = rank['score'] / total
    rank['cum_pct'] = rank['norm'].cumsum()
    cut_idx = (rank['cum_pct'] >= CUM_THRESHOLD).idxmax()

selected_vars = rank.loc[:cut_idx, 'feature'].tolist()

print(f"\nTécnica: {METHOD} | Umbral: {CUM_THRESHOLD*100:.0f}%")
print(f"Variables seleccionadas ({len(selected_vars)}): {selected_vars}")

# ---------------------------------------------------------------
# Generar dataset final con variables seleccionadas + target
# ---------------------------------------------------------------
df_out = pd.concat([X[selected_vars], y.rename(TARGET_COL)], axis=1)
print(rank.head(10))
rank_cat = rank.copy()
selected_vars_cat = selected_vars.copy()
df_out_cat = pd.concat([X[selected_vars_cat], y.rename(TARGET_COL)], axis=1)

# ----------------- CONFIG Valores -----------------
METHOD        = "num_f"       # "cat_chi2" (categóricas) o "num_f" (numéricas)

# ---------------------------------------------------------------
# Elegir columnas categoricas
# ---------------------------------------------------------------
if METHOD == "cat_chi2":
    cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    if len(cols) == 0:
        raise ValueError("No hay columnas categóricas para Chi².")
elif METHOD == "num_f":
    cols = X.select_dtypes(include=[np.number]).columns.tolist()
    if len(cols) == 0:
        raise ValueError("No hay columnas numéricas para ANOVA F-test.")
else:
    raise ValueError("METHOD debe ser 'cat_chi2' o 'num_f'.")

X_use = X[cols].copy()

# ---------------------------------------------------------------
# Train/Test split (estratificado) y codificación del target
# ---------------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X_use, y, test_size=0.30, random_state=42, stratify=y
)

lab_y = LabelEncoder()
y_train_enc = lab_y.fit_transform(y_train)
y_test_enc  = lab_y.transform(y_test)

# ---------------------------------------------------------------
# Calcular "scores" según técnica del notebook
# ---------------------------------------------------------------
if METHOD == "cat_chi2":
    # Rellenar vacíos con 'MISSING' para no perder filas
    X_train_f = X_train.fillna('MISSING')

    # OrdinalEncoder (como en el notebook); unknown -> -1
    ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
    X_train_enc = ord_enc.fit_transform(X_train_f)

    # Desplazar +1 para que todo sea >= 0 (Chi² lo requiere)
    X_train_enc = X_train_enc + 1

    # Chi² sobre TODAS las columnas (k='all') para obtener score por variable
    selector_all = SelectKBest(score_func=chi2, k='all')
    selector_all.fit(X_train_enc, y_train_enc)

    scores = np.nan_to_num(selector_all.scores_, nan=0.0)
    rank = (
        pd.DataFrame({'feature': cols, 'score': scores})
        .sort_values('score', ascending=False)
        .reset_index(drop=True)
    )

elif METHOD == "num_f":
    # ANOVA F-test sobre numéricas (no necesita encoding)
    selector_all = SelectKBest(score_func=f_classif, k='all')
    selector_all.fit(X_train.values, y_train_enc)

    scores = np.nan_to_num(selector_all.scores_, nan=0.0)
    rank = (
        pd.DataFrame({'feature': cols, 'score': scores})
        .sort_values('score', ascending=False)
        .reset_index(drop=True)
    )

# ---------------------------------------------------------------
# Selección por % acumulado (score normalizado)
# ---------------------------------------------------------------
total = rank['score'].sum()
if total == 0:
    # Si todos los scores son 0, nos quedamos con la primera para cumplir
    rank['norm'] = 0.0
    rank['cum_pct'] = 0.0
    cut_idx = 0
else:
    rank['norm'] = rank['score'] / total
    rank['cum_pct'] = rank['norm'].cumsum()
    cut_idx = (rank['cum_pct'] >= CUM_THRESHOLD).idxmax()

selected_vars = rank.loc[:cut_idx, 'feature'].tolist()

print(f"\nTécnica: {METHOD} | Umbral: {CUM_THRESHOLD*100:.0f}%")
print(f"Variables seleccionadas ({len(selected_vars)}): {selected_vars}")

# ---------------------------------------------------------------
# Selección por % acumulado (score normalizado)
# ---------------------------------------------------------------
total = rank['score'].sum()
if total == 0:
    # Si todos los scores son 0, nos quedamos con la primera para cumplir
    rank['norm'] = 0.0
    rank['cum_pct'] = 0.0
    cut_idx = 0
else:
    rank['norm'] = rank['score'] / total
    rank['cum_pct'] = rank['norm'].cumsum()
    cut_idx = (rank['cum_pct'] >= CUM_THRESHOLD).idxmax()

selected_vars = rank.loc[:cut_idx, 'feature'].tolist()

print(f"\nTécnica: {METHOD} | Umbral: {CUM_THRESHOLD*100:.0f}%")
print(f"Variables seleccionadas ({len(selected_vars)}): {selected_vars}")

# ---------------------------------------------------------------
# Generar dataset final con variables seleccionadas + target
# ---------------------------------------------------------------
df_out = pd.concat([X[selected_vars], y.rename(TARGET_COL)], axis=1)
print(rank.head(10))
rank_num = rank.copy()
selected_vars_num = selected_vars.copy()
df_out_num = pd.concat([X[selected_vars_num], y.rename(TARGET_COL)], axis=1)

# ======= UNIÓN FINAL: columnas seleccionadas de ambos ============
final_vars = sorted(set(selected_vars_cat) | set(selected_vars_num))

df_final = pd.concat([X[final_vars], y.rename(TARGET_COL)], axis=1)
print(f"Vars cat: {len(selected_vars_cat)} | Vars num: {len(selected_vars_num)} | Unión: {len(final_vars)}")
print(df_final.shape)

df_final.head()

